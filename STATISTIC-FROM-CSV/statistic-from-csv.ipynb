{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "# Load the data from the CSV files\n",
    "cosine_similarity_data = pd.read_csv('cosine_similarity_monthly.csv')\n",
    "test_results_data = pd.read_csv('test_results_monthly.csv')\n",
    "\n",
    "# Extract cosine similarity data\n",
    "cosine_similarity_data = cosine_similarity_data['Cosine Similarity'].dropna().tolist()\n",
    "\n",
    "precision_data = []\n",
    "recall_data = []\n",
    "f1_score_data = []\n",
    "\n",
    "# Iterate through the 'macro avg' column to extract precision and recall\n",
    "for item in test_results_data['macro avg']:\n",
    "    metrics = literal_eval(item)  # Convert string to dictionary\n",
    "    precision_data.append(metrics['precision'])\n",
    "    recall_data.append(metrics['recall'])\n",
    "    f1_score_data.append(metrics['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapiro-Wilk Test for Normality\n",
    "This test will help determine if the variables have a normal distribution, which is a prerequisite for performing Pearson's correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# Function to perform Shapiro-Wilk test\n",
    "def shapiro_wilk_test(data, alpha=0.05):\n",
    "    stat, p = shapiro(data)\n",
    "    print('Statistics=%f, p=%f' % (stat, p))\n",
    "    if p > alpha:\n",
    "        print('Sample looks normally distributed')\n",
    "    else:\n",
    "        print('Sample does not look normally distributed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute Shapiro-Wilk test on f1-score and cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing if the recall values have a normal distribution\n",
    "print(\"Recall Shapiro-Wilk Test:\")\n",
    "shapiro_wilk_test(recall_data)\n",
    "# Testing if the precision values have a normal distribution\n",
    "print(\"Precision Shapiro-Wilk Test:\")\n",
    "shapiro_wilk_test(precision_data)\n",
    "# Testing if the cosine similarity values have a normal distribution\n",
    "print(\"Cosine Similarity Shapiro-Wilk Test:\")\n",
    "shapiro_wilk_test(cosine_similarity_data)\n",
    "# Testing if the f1-score values have a normal distribution\n",
    "print(\"F1-Score Shapiro-Wilk Test:\")\n",
    "shapiro_wilk_test(f1_score_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Pearson Correlation Coefficient\n",
    "This section calculates Pearson's correlation coefficient to explore the relationship between the F1 scores and cosine similarity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "def pearson(data):\n",
    "    pearson_corr, p_value = pearsonr(data, cosine_similarity_data)\n",
    "\n",
    "    print(f\"Correlation coefficient: {pearson_corr}\")\n",
    "    print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Calculate Pearson's correlation coefficient for precision\n",
    "print(\"Precision Pearson's Correlation:\")\n",
    "pearson(precision_data)\n",
    "# Calculate Pearson's correlation coefficient for recall\n",
    "print(\"Recall Pearson's Correlation:\")\n",
    "pearson(recall_data)\n",
    "# Calculate Pearson's correlation coefficient for f1-score\n",
    "print(\"F1-Score Pearson's Correlation:\")\n",
    "pearson(f1_score_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Spearman Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "def spearman(data):\n",
    "    # Calculate Spearman's correlation coefficient between F1 scores and cosine similarity\n",
    "    spearman_corr, spearman_p_value = spearmanr(data, cosine_similarity_data)\n",
    "\n",
    "    print(f\"Correlation coefficient: {spearman_corr}\")\n",
    "    print(f\"P-value: {spearman_p_value}\")\n",
    "    \n",
    "# Calculate Spearman's correlation coefficient for precision\n",
    "print(\"Precision Spearman's Correlation:\")\n",
    "spearman(precision_data)\n",
    "# Calculate Spearman's correlation coefficient for recall\n",
    "print(\"Recall Spearman's Correlation:\")\n",
    "spearman(recall_data)\n",
    "# Calculate Spearman's correlation coefficient for f1-score\n",
    "print(\"F1-Score Spearman's Correlation:\")\n",
    "spearman(f1_score_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
